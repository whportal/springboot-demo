spring:
  # Kafka 配置项，对应 KafkaProperties
  kafka:
    # 指定 Kafka Broker 地址，可以设置多个，以逗号分隔
    bootstrap-servers: 192.168.125.128:9092,192.168.125.129:9092,192.168.125.130:9092
    # Kafka Producer 配置项
    producer:
      # 0-不应答。1-leader 应答。all-所有 leader 和 follower 应答
      # 当使用 kafka 的事务消息时需要修改为 all，否则启动会报错，因为 kafka 的事务消息需要基于幂等性来实现，所以必须保证所有节点都写入成功
      acks: 1
      # 发送失败时，重试发送的次数
      retries: 3
      # 消息的 key 的序列化
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      # 消息的 value 的序列化
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      # 每次批量发送消息的最大数量
      batch-size: 16384
      # 每次批量发送消息的最大内存
      buffer-memory: 33554432
      properties:
        linger:
          # 此处设置的值仅为了测试 实际生产环境中需要根据实际情况进行调整
          # 批处理延迟时间上限。这里配置 30 * 1000 ms 过后，不管消息数量是否达到 batch-size 或者消息大小达到 buffer-memory 都直接发送一次请求
          ms: 30000
      # 事务编号前缀，需要保证相同应用配置相同，不用应用配置不同
      transaction-id-prefix: demo.
    # Kafka Consumer 配置项
    consumer:
      # 设置消费者分组最初的消费进度为 earliest
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      # poll 一次拉取的阻塞的最大时长，单位：毫秒。这里指的是阻塞拉取需要满足至少 fetch-min-size 大小的消息
      fetch-max-wait: 10000
      # poll 一次消息拉取的最小数据量，单位：字节
      fetch-min-size: 10
      # poll 一次消息拉取的最大数量
      max-poll-records: 100
      properties:
        spring:
          json:
            trusted:
              # 因为 JsonDeserializer 在反序列化消息时，考虑到安全性，只反序列化程信任的 Message 类
              packages: com.wh.kafka.message
      # 读取已提交的消息
      isolation-level: read_committed
      # 使用 Spring-Kafka 的消费进度的提交机制
      enable-auto-commit: false
    # Kafka Consumer Listener 监听器配置
    listener:
      # 监听器类型，默认为 single，只监听单条消息，这里我们配置 batch，监听多条消息，批量消费
      type: single
      # 消费监听接口监听的主题不存在时，默认会报错，所以通过设置为 false，解决报错
      missing-topics-fatal: false
      # 使用 manual 模式，调用时，先标记提交消费进度，等到当前消息被消费完成后，然后再提交消费进度
      ack-mode: manual
logging:
  level:
    org:
      springframework:
        # spring-kafka INFO 日志太多了，限制
        kafka: ERROR
      apache:
        # kafka INFO 日志太多
        kafka: ERROR
